{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-allahkhani/InfoRetrieval/blob/main/IR_PH2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers langchain PyMuPDF llama-cpp-python\n"
      ],
      "metadata": {
        "id": "wR9w_4QeUqZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz\n",
        "import fitz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4W4t86lyKFvB",
        "outputId": "1df64d87-630f-4455-95c3-11669f5892d4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-7.0.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (4.0.2)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.8.6-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.0.3)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6.2-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->fitz) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (67.7.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.3)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.0-py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson>=3.8.0 (from nipype->fitz)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traits!=5.0,<6.4,>=4.6 (from nipype->fitz)\n",
            "  Downloading traits-6.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.14.0)\n",
            "Collecting etelemetry>=0.2.0 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Collecting looseversion (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.1)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.2.0->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2024.2.2)\n",
            "Installing collected packages: looseversion, traits, simplejson, isodate, configparser, configobj, ci-info, rdflib, pyxnat, etelemetry, prov, nipype, fitz\n",
            "Successfully installed ci-info-0.3.0 configobj-5.0.8 configparser-7.0.0 etelemetry-0.3.1 fitz-0.0.1.dev2 isodate-0.6.1 looseversion-1.3.0 nipype-1.8.6 prov-2.0.0 pyxnat-1.6.2 rdflib-7.0.0 simplejson-3.19.2 traits-6.3.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'frontend'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ba4c3e078a3e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install fitz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fitz/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfrontend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0.0.1dev2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'frontend'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO70dYluU8uB",
        "outputId": "20eef7b3-6c85-4d86-d2e0-c7f4630ac2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.5)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.3 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "pdf_path = '/content/10.1109_isspit.2005.1577093_fdcf.pdf'\n",
        "# pdf_path = '/content/IPSec VPN Lab.pdf'\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "print(pdf_text)  # Print the first 500 characters of the extracted text"
      ],
      "metadata": {
        "id": "rPt1Rth3t_M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdd101b-5b1e-4026-a974-30cbde41c642",
        "collapsed": true
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Motion Detection Using Differential Histogram Equalization \n",
            "R. Hasanzadeh P.R.*, A. Shahmirzaie**, A.H. Rezaie***  \n",
            "Electrical Engineering Department, \n",
            "Amirkabir University of Technology,  \n",
            "Hafez Avenue, Tehran, 15914, Iran. \n",
            "Emails: hasanzadeh@aut.ac.ir*; shahmirzaie@aut.ac.ir**;rezaie@aut.ac.ir*** \n",
            " \n",
            "Abstract-In attention to general motion detection methods, \n",
            "differential sequences of frames make some convenience \n",
            "which expand it’s usability for lots of applications. In \n",
            "practice, differential sequences of frames have been affected \n",
            "by environmental noises and CCD cameras structure that \n",
            "make difficulty detection in volubility of objects. In this \n",
            "method using differential histogram equalization, we try to \n",
            "enhance and increase the contrast between data and noise \n",
            "histogram levels. The new threshold levels adaptively \n",
            "obtained by simple algorithm and doesn’t need to know \n",
            "probability distribution function of the noise.  \n",
            " \n",
            "Keywords– Motion Detection, Histogram Equalization, Adaptive \n",
            "Threshold. \n",
            " \n",
            "I. INTRODUCTION \n",
            " \n",
            "Motion detection based on video signals is widely used in \n",
            "security systems, airports and military bases etc. [1, 2 and 3]. \n",
            "The situation is usually the detection of the movement of an \n",
            "object in a constant background. In other words it is assumed \n",
            "that the position of the camera is fixed.  Several methods are \n",
            "used to motion detection, such as Dynamic Time Warping, \n",
            "Hidden Markov models and Neural Networks [12], but usual \n",
            "method is to use the two consecutive frames having the \n",
            "knowledge of the probability density function of the noise, \n",
            "possible to extract some sections of the differential histogram \n",
            "levels which have the most probability of the helpful data [3, \n",
            "and 4].     \n",
            " \n",
            " \n",
            "Fig. 1a. \n",
            "Fig. 1b. \n",
            "     In these methods the necessity of having the knowledge of \n",
            "environmental noise, limits its wide uses in automatic control \n",
            "systems [5, and 6]. Efforts of applying any adaptive method \n",
            "for the threshold levels involve algorithms like K- Means \n",
            "which are time consuming [8]. Usually high precision \n",
            "boundary detection using likelihood ratio is not essential in \n",
            "security systems (Fig. 1a) but also pattern recognition in \n",
            "security systems is based on motion detection assumed on \n",
            "motion existence. On the other hand it is preferred the \n",
            "ambiguous region which is between motion and silence \n",
            "regions to be realized as the class of movement (Fig. 1b). \n",
            "Comparing Fig. 1a with Fig. 1b, we notice that the Bayes test \n",
            "for minimum cost is a likelihood ratio test with a different \n",
            "threshold from Bayes test for minimum error [11].  \n",
            "    In these systems the second priority after the motion \n",
            "detection is the speed of data processing. Increasing the speed \n",
            "of process causes an immediate result to the expert operator \n",
            "and the central control system. Therefore although accurate \n",
            "motion detection may be achieved by iterative methods, \n",
            "because of their long calculations time may not be used in \n",
            "real time systems. \n",
            " \n",
            "II. METHOD DESCRIPTION \n",
            " \n",
            "Detection of motion in images can be obtained by \n",
            "investigating of frames. One of the methods for motion \n",
            "detection is based on using of two sequential frames. \n",
            "Differential histograms of two frames contain Gaussian noise \n",
            "with zero mean caused of CCD camera sensors [9]. In \n",
            "practice, its variance has small variation specifically for \n",
            "objects that contain motions smaller than 1/8 of space area. \n",
            "Fig. 2 shows a differential histogram without motion which \n",
            "obtained in practice. Here we use a gray scale CCD camera \n",
            "with 256 brightness levels (8 bit). \n",
            "As a result of discrete brightness level problem and small \n",
            "variation of variances, the number of fundamentals levels of \n",
            "differential histograms which contains at least 5% of \n",
            "amplitude of the level at zero mean range is less than twenty. \n",
            "Hence, obtaining the variance of Gaussian distribution \n",
            "function has some problem. The number of threshold level \n",
            "(handled or adaptive) used for extract motion from noise, is \n",
            "more than 10. In differential histogram space nearly all of \n",
            " \n",
            "Fig. 2. Shows Differential histogram without motion \n",
            "186\n",
            "0-7803-9314-7/05/$20.00©2005 IEEE\n",
            "2005 IEEE International \n",
            "Symposium on Signal Processing\n",
            "and Information Technology\n",
            "variations are between [-100,100]. The motions comparable \n",
            "with whole of image space, for example ¼ or ½ of entire area \n",
            "of image are detected without any complex algorithms only \n",
            "use a simple threshold. Generally, the complexity of \n",
            "problems is obtaining a solution to detection of nearly small \n",
            "motions in image space because differential histogram levels \n",
            "of motion concentrated around of differential histogram \n",
            "levels of noise.  \n",
            "Hence, specification of threshold levels is very sensitive \n",
            "which is shown in Fig. 3. The Fig. 3 shows a differential \n",
            "histogram (DH) levels which can be extracted in practice. \n",
            "The TR and TL, point to the threshold levels that one can set \n",
            "handled or adaptive to separate the motion from the noise and \n",
            "the background.  \n",
            " \n",
            "Fig. 4a. DH before motion \n",
            " \n",
            "Fig. 4b. DH after motion \n",
            "Also in practice the DH have some oscillations around the \n",
            "zero mean level that is due to the fast motions. Differential \n",
            "histogram equalization or DHE increase image enhancement \n",
            "and contrast of brightness levels and remove threshold level \n",
            "variation is caused by DH oscillation (See equation (3)).  The \n",
            "Fig. 4 shows a DH before and after motion in image. \n",
            "Differential levels continuously have a nonzero value in all of \n",
            "the levels between [-20, 20] and after motion between [-\n",
            "100,100]. If DH threshold levels changes only one level, it \n",
            "might neglect remarkable volume of data or impose noise to \n",
            "motion detection. Fig. 5 shows DHE before and after motion \n",
            "for Fig. 4. Probability of unwanted oscillation’s effect is \n",
            "minimized by high contrast of brightness level. Aggregations \n",
            "of brightness levels in two corners of DHE belong to motion \n",
            "and in centre of DHE with high distance between levels \n",
            "belong to noise. \n",
            " \n",
            "Fig. 5a. DHE before motion \n",
            " \n",
            "Fig. 5b. DHE after motion \n",
            " \n",
            "III. DIFFERENTIAL HISTOGRAM EQUALIZATION \n",
            " \n",
            " \n",
            "Fig. 6. Shows stages of \n",
            "motion detection \n",
            " Attention to Fig. 6, video capture system provides images \n",
            "then these images are used in sequences of differential frames \n",
            "obtaining differential histograms. Histogram equalization \n",
            "[10] uses for enhancing brightness levels of one image but \n",
            "here we applies it for enhancing differential brightness levels \n",
            "of sequential frames.  \n",
            "Percentage of each brightness level computed by equation \n",
            "(1): \n",
            "k\n",
            "r\n",
            "n\n",
            "P [K]\n",
            "255\n",
            "K\n",
            "255\n",
            "n\n",
            "=\n",
            "−\n",
            "≤\n",
            "≤\n",
            "                  (1) \n",
            " \n",
            "Fig. 3. Shows Differential histogram with motion \n",
            "187\n",
            "k\n",
            "n : The number of pixels with K differential brightness \n",
            "level.  \n",
            "k\n",
            "j\n",
            "k\n",
            "j 0\n",
            "n\n",
            "S\n",
            "CDF[k]\n",
            "n\n",
            "=\n",
            "=\n",
            "= ∑\n",
            "                                       (2) \n",
            "k\n",
            "S , cumulative distribution function, is new differential \n",
            "brightness level. Percentage of each new brightness level \n",
            "computed by equation (3): \n",
            " \n",
            "s\n",
            "k\n",
            "r\n",
            "j\n",
            "j\n",
            "j\n",
            "k\n",
            "P [K.S ]\n",
            "P [K.S ]\n",
            "for\n",
            "[K.S ]\n",
            "[K.S ]\n",
            "=\n",
            "=\n",
            "∑\n",
            "                                     (3) \n",
            " \n",
            "Equation (3) converts a number of the adjacent brightness \n",
            "levels that occurred with small amplitude, to one brightness \n",
            "level with remarkable amplitude. Different between Figs. 4 \n",
            "and 5 shows it.  \n",
            " \n",
            " \n",
            "IV. ADAPTIVE THRESHOLD \n",
            " \n",
            "As a previous discussion, motions contain big area and \n",
            "motions with high contrast relative to background doesn’t \n",
            "need to complex or high precision algorithm because these \n",
            "motion can be detected simply. The problem is detection of \n",
            "motions with brightness levels near to background or motions \n",
            "with small area. Two last properties cause to: (1) low \n",
            "amplitude of motion brightness levels, (2) ling motion \n",
            "brightness level near the center of DHE which the noise \n",
            "levels stand here. After DHE which is shown in Fig. 5, we try \n",
            "to detect a threshold adaptively. The thresholds calculated as \n",
            "nonzero continuous brightness levels with a number of \n",
            "specific zero amplitude level after them. Because of small \n",
            "and low variation, after DHE brightness levels of motion \n",
            "have a continuously state at the corner of histogram. \n",
            "Threshold between motions levels and noise can be \n",
            "calculated by counting the continuous brightness levels with \n",
            "zero amplitude between them. Numbers of allowable zero \n",
            "amplitude levels depend to motion area and brightness \n",
            "variation. Usually, it is equals two. \n",
            "Fig. 7 shows the flowchart for obtaining the thresholds. \n",
            "i\n",
            "R\n",
            "H  \n",
            "Shows the Right side of DHE and \n",
            "j\n",
            "L\n",
            "H shows the Left side of \n",
            "it { i\n",
            "(0,255], j\n",
            "[ 255,0)\n",
            "∈\n",
            "∈−\n",
            "}. TR and TL are Right and Left \n",
            "threshold levels of DHE. ZR and ZL shows continuous \n",
            "brightness levels with zero amplitude from the two corners \n",
            "re-entrant to centre of DHE. X is the numbers of allowable \n",
            "continuous levels with zero amplitude that usually is 2. \n",
            " \n",
            "V. EXPERIMENTAL RESULT \n",
            " \n",
            "We apply the method for detection the motion in PC based \n",
            "security systems. The size of images was 320*240 in eight bit \n",
            "Gray scale format. The motion has been detected from two \n",
            "sequential images which were obtained from video capture \n",
            "system. The simple but reliable and adaptive thresholding by \n",
            "using DHE can allow us to real-time surveillance. Fig. 8a \n",
            "shows the original image which is obtained from video \n",
            "capture system. The speed of video capturing system was 25 \n",
            "frames per second that in addition to processing decreases to \n",
            "20 frames per second. The result of difference of two \n",
            "sequential images is shown in Fig. 8b. In order to find the \n",
            "region of the moving object it is necessary to determine a \n",
            "closed contour around the detected motion. This may be done \n",
            "by first the differentiation of two consecutive frames \n",
            "following DHE calculations which is shown in Fig. 8c and \n",
            "applying the algorithm mentioned in section (IV) which \n",
            "results to Fig. 8d. The number of nonzero continuous \n",
            "brightness levels (ZL and ZR) that is used here are two. The \n",
            "some simple and small noise which is remained can be \n",
            "removed by morphological processing [10]. It is done by two \n",
            "stages of Morphology algorithm (Dilation/Erosion) followed \n",
            "by using the remove particle algorithms will lead to figure (8-\n",
            "e). In this case a uniform and binary region of the moving \n",
            "object will be achieved by using the filling algorithm as \n",
            "shown if Fig. 8f.  \n",
            "   Also it is necessary to find out a rectangle around the \n",
            "moving object. The number of rectangles depends on the \n",
            "number of motion detected regions in each camera which is \n",
            "shown in Fig. 8f. \n",
            "It is not necessary to transmit the entire image, because the \n",
            "background of the images is constant. We just extract the \n",
            "moving images from the boundary that was obtained as Fig. \n",
            "8f. The results of the moving objects from the Fig. 8a are \n",
            "shown in Figs. 8g and 8h. Finally, extracted images from \n",
            "moving object are sent through LAN and/or Modem to \n",
            "Central Security System. \n",
            " \n",
            "VI. CONCLUSION \n",
            " \n",
            "In some application such as security systems it is necessary \n",
            "using of methods which are fast, reliable and simple. Usually \n",
            "high precision boundary detection using likelihood ratio is \n",
            "not essential in security systems but also detection of motion \n",
            "is vital. In this method using differential histogram \n",
            "equalization, we try to minimize the cost for the motion class \n",
            "by enhancing and increasing the contrast between motion and \n",
            "no-motion histogram levels. The new threshold levels \n",
            "adaptively obtained by simple algorithm and doesn’t need to \n",
            "know probability distribution function of the noise. This \n",
            "method is applied for monitoring and security system of \n",
            "Electrical and Mechanical Eng. Departments of Amirkabir \n",
            "University (10 floors and 30 cameras). The result of it had \n",
            "good efficiency for fast detection of motion and cause to \n",
            "reduce the human inspection fault. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "188\n",
            "ACKNOWLEDGEMENT \n",
            " \n",
            "The authors would like to thank Mr. Javad Ostadreza, \n",
            "Administrator of Computer Networks, Department of \n",
            "Electrical Engineering, for helping to design the monitoring \n",
            "and security system of Electrical and Mechanical Eng. \n",
            "Departments, Amirkabir University of Technology. \n",
            " \n",
            " \n",
            "REFERENCES \n",
            " \n",
            "[1] McKenna, SJ. , Jabri, S., Duric, Z., Rosenfeld, Wechsler, H., “Tracking \n",
            "groups of people” Int. J. Comput. Vision Image Understanding, vol. 80, pp. \n",
            "42-56, 2000. \n",
            "[2] Sukthankar, R., Stockton, R., “Argues: the digital doorman” IEEE Trans. \n",
            "Intell. System, vol. 16(2), pp. 14-19, 2001. \n",
            "[3] Kim, J.B., Lee, C.W., Hwang, S.W., Kim, H.J. “A real time moving \n",
            "object detection for video monitoring system”  Proc. ITC-CSCC 1, pp. 454-\n",
            "457,2001b. \n",
            "[4] Nariman, H., Alireza, M., Neil, B., “Automatic thresholding for change \n",
            "detection in digital video” Proc. SPIE 4067, pp. 133-142, 2000. \n",
            "[5]Kittler, J. Illingworth, J., “Minimum error thresholding pattern \n",
            "recognition”, vol. 19 (1), pp. 41-47, 1986. \n",
            "[6] Aach, T., Kaup, A., Mester, R., “Statistical model-based change \n",
            "detection in moving video” Signal Processing, Vol. 31, pp.165-180, 1993. \n",
            "[7] Kim, M., Chai, J.G., Kim, D., Lee, H., Lee, M.H., Ahn, C., Ho, Y.s., “A \n",
            "vop generation tool: Automatic segmentation of moving objects in image \n",
            "sequences based on spatio-temporal information” IEEE Trans. Circuits Sys. \n",
            "Video Tech., Vol. 9, no. 8, pp. 1216-1226, 1999.   \n",
            "[8] Kim, J.B., Kim, H.J.,”Efficient region-based motion segmentation for \n",
            "video monitoring system” Pattern recognition, vol. 24 (3), pp. 113-128, 2003. \n",
            "[9] Teklap, A.M., Digital video processing, Prentice Hall, upper saddle river, \n",
            "NJ, 1995. \n",
            "[10] Gonzalez, R. C., and Woods, R. E., Digital Image Processing, Addison-\n",
            "Wesley Publishing Company, Massachusetts, 1992. \n",
            "[11] K. Fukunaga, Introduction to Statistical Pattern Recognition, Academic \n",
            "Press, INC, 1992. \n",
            "[12] L. Wang, W. Hu, T. Tan, “Recent Development in human motion \n",
            "analysis”, Pattern Recognition, vol. 36, pp. 585-601, 2003. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Fig. 7. Shows the flowchart to \n",
            "achieving  to thresholds \n",
            "189\n",
            " \n",
            " \n",
            " \n",
            "Fig. 8a.  The Original Image \n",
            "Fig. 8b. The result of difference of two \n",
            "sequential images \n",
            "Fig. 8c. After Differential Histogram \n",
            "Equalization \n",
            " \n",
            " \n",
            " \n",
            "Fig. 8d. The result of adaptive thresholding \n",
            "Fig. 8e. Particle removing \n",
            "Fig. 8f. Motion boundary detection \n",
            " \n",
            " \n",
            " \n",
            "Fig. 8g. First moving object \n",
            "Fig. 8h. Second moving object \n",
            " \n",
            " \n",
            "190\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C2X98DcMszBB",
        "outputId": "d2ce1f62-4d28-427d-ddb1-918b214d04ae"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m174.1/224.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, size):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    for word in words:\n",
        "        if len(current_chunk) < size:\n",
        "            current_chunk.append(word)\n",
        "        else:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fWny3oSX0tV5"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = chunk_text(pdf_text, 20)\n",
        "print(texts[11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah4761mX6dKR",
        "outputId": "1e8e22b2-89ea-4775-d9b2-8a526141ba33"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of the differential histogram levels which have the most probability of the helpful data [3, and 4]. Fig. 1a. Fig.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Load model for embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "doc = []\n",
        "for text in texts:\n",
        "  doc.append(text)\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(doc)\n",
        "\n",
        "# Example: Print the shape of the embeddings\n",
        "print(\"Embeddings shape:\", np.array(embeddings).shape)\n",
        "\n",
        "# # Example: Use embeddings for finding the most similar sentence\n",
        "query = \"The TR and TL\"\n",
        "query_embedding = model.encode(query)\n",
        "similarities = np.dot(embeddings, query_embedding)\n",
        "\n",
        "most_similar_idx = np.argmax(similarities)\n",
        "print(most_similar_idx)\n",
        "print(\"Most similar sentence:\", texts[most_similar_idx])\n"
      ],
      "metadata": {
        "id": "4ydU4ADpsEfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d42716-37b5-42af-da48-b24b25389790"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (372, 384)\n",
            "234\n",
            "Most similar sentence: }. TR and TL are Right and Left \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vf-6Lspt4bx",
        "outputId": "00707f25-3dba-4866-ac06-8c130da98b23"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.01887396 -0.04114674  0.03448933 ... -0.10015821  0.00326166\n",
            "  -0.04016942]\n",
            " [-0.01783551  0.06279813 -0.12179976 ...  0.00130641  0.06793331\n",
            "  -0.05076052]\n",
            " [-0.07920266  0.05690813  0.02745926 ...  0.02077965  0.02444942\n",
            "   0.01808143]\n",
            " ...\n",
            " [-0.11883845  0.04829863 -0.00254808 ...  0.12640949  0.04654901\n",
            "  -0.01571721]\n",
            " [-0.11883845  0.04829863 -0.00254808 ...  0.12640949  0.04654901\n",
            "  -0.01571721]\n",
            " [-0.06357609  0.05496175 -0.08032549 ... -0.08256663 -0.14181998\n",
            "  -0.04115086]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKqv2TUcxGtZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}